# -*- coding: utf-8 -*-
"""Senior Thesis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MwzQY0MewGnoSDXzFWgM9xqoGHcIqsnF
"""

# ============================================
# Pairwise Johansen + Mean-Reversion Model
# for Corporate Bond Issuer Yields
# ============================================

# --- 0. Imports ---
import numpy as np
import pandas as pd
import itertools
import statsmodels.api as sm
from statsmodels.tsa.vector_ar.vecm import coint_johansen

# If you're in Google Colab, uncomment the next lines to upload BTDS.csv:
# from google.colab import files
# uploaded = files.upload()  # then choose BTDS.csv
# FILE_NAME = list(uploaded.keys())[0]

# If the file is already in your Colab working directory, just set:
FILE_NAME = "BTDS.csv"   # change this if your file has a different name

# --- 1. Load and clean TRACE-style data ---

print(f"Loading {FILE_NAME} ...")
df = pd.read_csv(FILE_NAME)

# Expecting at least these columns: trd_exctn_dt, company_symbol, yld_pt
required_cols = {"trd_exctn_dt", "company_symbol", "yld_pt"}
missing = required_cols - set(df.columns)
if missing:
    raise ValueError(f"Missing required columns in CSV: {missing}")

# Parse date and convert yld_pt to numeric
df["trd_exctn_dt"] = pd.to_datetime(df["trd_exctn_dt"])
df["yld_pt"] = pd.to_numeric(df["yld_pt"], errors="coerce")

# Drop rows with missing yield or company symbol
df = df.dropna(subset=["company_symbol", "yld_pt"])

print("Number of trades after cleaning:", len(df))

# --- 2. Build daily median yield per company ---

daily_yields = (
    df.groupby(["trd_exctn_dt", "company_symbol"])["yld_pt"]
      .median()
      .reset_index()
)

panel = daily_yields.pivot(index="trd_exctn_dt",
                           columns="company_symbol",
                           values="yld_pt").sort_index()

print("Panel shape (dates x companies):", panel.shape)
print("Companies found:", list(panel.columns))

# Optionally filter to companies with enough observations
min_days_per_company = 10
valid_cols = [c for c in panel.columns if panel[c].count() >= min_days_per_company]
panel = panel[valid_cols]
print("Companies kept after min-days filter:", len(valid_cols))

# --- 3. Helper: Johansen test for a pair of series ---

def johansen_cointegration_test(series1, series2, det_order=0, k_ar_diff=1, significance=0.95):
    """
    Run Johansen test on a 2xT matrix of levels.
    Returns (is_cointegrated, beta_vector, trace_stat, crit_value).
    """
    data = np.column_stack([series1, series2])

    # Johansen expects no NaNs
    data = data[~np.isnan(data).any(axis=1)]
    if data.shape[0] < 10:
        return False, None, np.nan, np.nan

    jres = coint_johansen(data, det_order=det_order, k_ar_diff=k_ar_diff)

    # For 2 variables, rank >= 1 if trace stat for r=0 exceeds critical value
    trace_stat = jres.lr1[0]           # test statistic for r=0
    crit_95 = jres.cvt[0, 1]          # 95% critical value

    is_coint = trace_stat > crit_95

    # First eigenvector as cointegration vector beta (normalize on first element = 1)
    beta = jres.evec[:, 0]
    beta = beta / beta[0]

    return is_coint, beta, trace_stat, crit_95

# --- 4. Helper: AR(1) on residual -> mean reversion & half-life ---

def estimate_mean_reversion(residual):
    """
    Fits AR(1): e_t = a + phi * e_{t-1} + eps_t.
    Returns (phi, half_life, t_stat, n_obs).
    """
    e = pd.Series(residual).dropna()
    if len(e) < 10:
        return np.nan, np.nan, np.nan, len(e)

    e_lag = e.shift(1).dropna()
    e_now = e.loc[e_lag.index]

    X = sm.add_constant(e_lag.values)
    y = e_now.values
    model = sm.OLS(y, X).fit()

    a = model.params[0]
    phi = model.params[1]
    t_stat = model.tvalues[1]
    n_obs = int(model.nobs)

    if abs(phi) < 1:
        half_life = -np.log(2) / np.log(abs(phi))
    else:
        half_life = np.inf

    return phi, half_life, t_stat, n_obs

# --- 5. Loop over all company pairs and test relationships ---

min_overlap_days = 15   # require at least this many overlapping days for a pair

results = []

companies = list(panel.columns)
print(f"Running pairwise tests over {len(companies)} companies "
      f"({len(companies)*(len(companies)-1)//2} pairs).")

for c1, c2 in itertools.combinations(companies, 2):
    pair_df = panel[[c1, c2]].dropna()
    n_overlap = len(pair_df)
    if n_overlap < min_overlap_days:
        continue

    # Johansen cointegration test
    is_coint, beta, trace_stat, crit_95 = johansen_cointegration_test(
        pair_df[c1].values,
        pair_df[c2].values
    )

    if not is_coint:
        results.append({
            "issuer_1": c1,
            "issuer_2": c2,
            "n_overlap_days": n_overlap,
            "cointegrated": False,
            "trace_stat": trace_stat,
            "crit_95": crit_95,
            "phi": np.nan,
            "half_life_days": np.nan,
            "phi_t_stat": np.nan
        })
        continue

    # If cointegrated, build residual and estimate AR(1) mean reversion
    S = pair_df[[c1, c2]].values
    residual = S @ beta  # beta' * [y1, y2]

    phi, half_life, phi_t, n_obs = estimate_mean_reversion(residual)

    results.append({
        "issuer_1": c1,
        "issuer_2": c2,
        "n_overlap_days": n_overlap,
        "cointegrated": True,
        "trace_stat": trace_stat,
        "crit_95": crit_95,
        "phi": phi,
        "half_life_days": half_life,
        "phi_t_stat": phi_t
    })

# --- 6. Collect results into a DataFrame and show top relationships ---

results_df = pd.DataFrame(results)

print("\nAll pairwise results (including non-cointegrated pairs):")
display(results_df)

# Filter to cointegrated, mean-reverting pairs (|phi| < 1)
cointegrated_df = results_df[
    (results_df["cointegrated"]) &
    (results_df["phi"].abs() < 1)
].copy()

# Sort by half-life (short to long)
cointegrated_df = cointegrated_df.sort_values("half_life_days")

print("\nCointegrated pairs with mean-reverting residuals (sorted by half-life):")
display(cointegrated_df)

# --- 7. Optionally, save results to CSV for later analysis ---

results_df.to_csv("pairwise_johansen_results_all_pairs.csv", index=False)
cointegrated_df.to_csv("pairwise_johansen_results_cointegrated.csv", index=False)

print("\nSaved:")
print(" - pairwise_johansen_results_all_pairs.csv")
print(" - pairwise_johansen_results_cointegrated.csv")